{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251f4289-3e18-466f-8ce0-f3d3121474d4",
   "metadata": {},
   "source": [
    "# 2025 ASAP CRN Colloborative Meeting - CRN Cloud Training Workshop Notebook #2\n",
    "\n",
    "## Overview\n",
    "This notebook is part 2: **Data Composition to create a smaller (more wieldy) _sub_- dataset**\n",
    "\n",
    "## Outline \n",
    "\n",
    "2. [`AnnData` Data Composition](#part-2-anndata-data-composition)\n",
    "    * Load unfiltered dataset `AnnData` object\n",
    "    * combine with _processed_ artifacts (`adata.obs`) \n",
    "    * Subset to a single brain region and Case-Contol group (from _dataset_ metadata)\n",
    "        * annotate cell metadata with dataset metadata\n",
    "        * save full gene expression `anndata` for subset with full metadata annotation (_dataset_ and _cell_-level)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Notebooks\n",
    "All of this content can be found in shorter more specific notebooks.  E.g. During the workshop you can follow along for Parts 1 & 2, but should start with Part 3 ([03_GOI_analysis.ipynb](./03_GOI_analysis.ipynb))\n",
    "\n",
    "- This notebook [00_full_example_notebook.ipynb](./00_full_example_notebook.ipynb)\n",
    "    - Part 1 - [01_basic_EDA.ipynb](./01_basic_EDA.ipynb)  \n",
    "    - Part 2 - [02_dataset_composition.ipynb](./02_dataset_composition.ipynb)\n",
    "    - Part 3 - [03_GOI_analysis.ipynb](./03_GOI_analysis.ipynb)\n",
    "        - Part 3-R - [03-R_GOI_analysis.ipynb](./03-R_GOI_analysis.ipynb)\n",
    "    - Part 4 - [04_DE_analysis.ipynb](./04_DE_analysis.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "------------------------------\n",
    ">> NOTES\n",
    ">>   need to develop an equivalent R version for part 1,2, and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a1c36",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4215af7d-4dcd-4cb8-ab82-2999c642dc27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 252 μs (started: 2025-03-06 08:52:12 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Use pathlib for file path manipulation\n",
    "from pathlib import Path \n",
    "\n",
    "\n",
    "# matplotlib and seaborn a pythonic alternative to plotnine\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError as e:\n",
    "    print(\"Error -> \", e)\n",
    "    print(\"Installing seaborn or matplotlib\")\n",
    "    !pip install matplotlib seaborn\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "try:\n",
    "    import scanpy as sc\n",
    "except ImportError as e:\n",
    "    print(\"Error -> \", e)\n",
    "    print(\"Installing scanpy\")\n",
    "    !pip install scanpy\n",
    "    import scanpy as sc\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "\n",
    "# Always show all columns in a Pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db0c4a-9383-4ecf-8462-b966b05e24d2",
   "metadata": {},
   "source": [
    "###  ASAP CRN data paths\n",
    "First, let's build the paths to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290f7e03-6997-4c35-9d14-1169ef794bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 682 μs (started: 2025-03-06 08:52:12 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Workspace Path\n",
    "HOME_PATH = Path.home()\n",
    "WS_PATH =  HOME_PATH / 'workspace'\n",
    "if not WS_PATH.exists():\n",
    "    print(f\"{WS_PATH} doesn't exist. We need to remount our resources\")\n",
    "    !wb resource mount    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4504cec7",
   "metadata": {},
   "source": [
    "We'll focus in on the datasets processed with our *PMDBS scRNAseq* workflow.  Specifically the _cohort_ dataset: `asap-cohort-pmdbs-sc-rnaseq`.  This dataset includes samples from 5 Contributing datasets which have been processesed and integrated.  The paths include the following parts.\n",
    "\n",
    "- `workflow` designates the workflow which performs the aggregation and integration.  In this case the [*PMDBS scRNAseq* workflow](https://github.com/ASAP-CRN/pmdbs-sc-rnaseq-wf)\n",
    "- `dataset_team` designates the contributing team for the dataset.  In this case _cohort_ designates that it is made from multiple individual contributed datasets.\n",
    "- `source` designates the _source_ of the samples.  In this case Post-mortem derived Brain samples\n",
    "- `dataset_type` designates the \n",
    "- `bucket_name` designates the datasets gcp bucket\n",
    "- `dataset_name` designates the unique designation for each dataset or collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55896468-d9d0-4f9b-97c5-864b329ecaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 759 μs (started: 2025-03-06 08:52:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "DATASETS_PATH = WS_PATH / \"01_PMDBS_scRNAseq_Datasets\"\n",
    "workflow = \"pmdbs_sc_rnaseq\"\n",
    "dataset_team = \"cohort\"\n",
    "dataset_source = \"pmdbs\"\n",
    "dataset_type = \"sc-rnaseq\"\n",
    "bucket_name = f\"asap-curated-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "dataset_name = f\"asap-{dataset_team}-{dataset_source}-{dataset_type}\"\n",
    "dataset_path = DATASETS_PATH / bucket_name / workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd4cc0",
   "metadata": {},
   "source": [
    "#### Cohort Analysis Path\n",
    "\n",
    "Now that we've defined the path to our cohort dataset, lets list the curated files for the `cohort_analysis`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb617d6-4503-4b74-ab79-a9511a4b2493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 357 μs (started: 2025-03-06 08:52:16 +00:00)\n"
     ]
    }
   ],
   "source": [
    "cohort_analysis_path = dataset_path / \"cohort_analysis\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e94a5-2b06-4f56-a439-3b904ac4b5ea",
   "metadata": {},
   "source": [
    "#### Dataset Metadata Path\n",
    "\n",
    "The dataset metadata can be found in the `release_resources`.  Note that the metadata are organized by the _short_ `dataset_name` rather than `bucket_name`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611b4a5a-a7ea-43b6-93c0-e60548238500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSAY_RNAseq.csv  CONDITION.csv  PMDBS.csv     SAMPLE.csv  SUBJECT.csv\n",
      "CLINPATH.csv\t  DATA.csv\t PROTOCOL.csv  STUDY.csv\n",
      "time: 854 ms (started: 2025-03-06 08:52:30 +00:00)\n"
     ]
    }
   ],
   "source": [
    "ds_metadata_path = WS_PATH / 'release_resources/asap-crn-cloud-release-resources' / dataset_name / \"metadata\"\n",
    "\n",
    "!ls {ds_metadata_path} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6936f6",
   "metadata": {},
   "source": [
    "#### Workshop/Notebook Artifact Path\n",
    "\n",
    "This is the path to where the artifacts we've created in these notebooks can be found in case you want to skip ahead.  Particularly for the workshop.  In which case you can replace the `local_data_path` with `WORKSHOP_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0383817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  notebooks\n",
      "time: 658 ms (started: 2025-03-06 08:52:40 +00:00)\n"
     ]
    }
   ],
   "source": [
    "WORKSHOP_PATH = WS_PATH / \"release_resources/asap-crn-cloud-release-resources/release-artifacts/2025_CRN_CM_Workshop_Resources_03122025\" \n",
    "\n",
    "!ls {WORKSHOP_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21a936",
   "metadata": {},
   "source": [
    "#### Local Data Path\n",
    "Lets also define a path for copying our data files and exporting intermediate analysis artifacts to your workspace.  In this example we'll make a \"workshop_files\" in the \"ws_files\" which are persistent in our Verily Workbench Workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f0a3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.94 ms (started: 2025-03-06 08:52:42 +00:00)\n"
     ]
    }
   ],
   "source": [
    "local_data_path = WS_PATH / \"workshop_files\"\n",
    "\n",
    "if not local_data_path.exists():\n",
    "    local_data_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b82a27",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "# Part 2: `AnnData` Data Composition \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122c6fe",
   "metadata": {},
   "source": [
    "\n",
    "The full `asap-cohort` PMDBS snRNAseq dataset contains gene expression (~36k genes) measurments of 2.7m cells.   We will subset to a smaller dataset of 290k prefrontal cortex cells.   \n",
    "\n",
    "We will make this `AnnData` artifact available as the resources of loading the full dataset and subsetting can be.\n",
    "\n",
    "An alternate strategy is to load each individual dataset individually, which is less resource intensive.  However, we would like to leverage the shared latent space for visualizations. \n",
    "\n",
    "\n",
    "Steps here.\n",
    "\n",
    "* Load unfiltered dataset `AnnData` object\n",
    "* combine with _processed_ artifacts (`adata.obs`) \n",
    "* Subset to a \"frontal_ctx\" brain region and Case-Contol group (from _dataset_ metadata)\n",
    "    * save full gene expression `anndata` for subset with full metadata annotation (_dataset_ and _cell_-level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ca771",
   "metadata": {},
   "source": [
    "### Subset by sample's brain region \n",
    "\n",
    "In the following we'll want to do a psuedo bulk differential expression analysis and also a simple meta-analysis over the individual contributions within the pan-ASAP CRN _cohort_ datasets.    Note that we are choosing to subset from the full asap-cohort so we can leverage the common UMAP.\n",
    "\n",
    "First we need to load the _dataset_ metadata from Part 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffaea319-5e2a-44b3-a37b-ff8d47522179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.1 ms (started: 2025-03-06 08:54:02 +00:00)\n"
     ]
    }
   ],
   "source": [
    "dataset_metadata_filen = local_data_path / \"asap-cohort-dataset-metadata.csv\"\n",
    "\n",
    "df = pd.read_csv(dataset_metadata_filen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73705ad7-ef99-482f-bb4d-812430dd06f4",
   "metadata": {},
   "source": [
    "And then we can make the mapings from sample IDs to the metadata values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833780ef-c04b-4bd7-b05f-d05e2be6817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.39 ms (started: 2025-03-06 08:54:17 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# define sample to match\n",
    "br_mapper_full = dict(zip(df[\"sample\"], df[\"brain_region\"]))\n",
    "br_mapper_simple = dict(zip(df[\"sample\"], df[\"brain_region_simple\"]))\n",
    "\n",
    "# Parkinsons and control samples\n",
    "condition_id_mapper = dict(zip(df[\"sample\"], df[\"condition_id\"]))\n",
    "case_id_mapper = dict(zip(df[\"sample\"], df[\"intervention_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09bb707a-dfda-4a81-8c29-cc7eccc1a330",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (truncated file: eof = 5634523136, sblock->base_addr = 0, stored_eof = 8513565110)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m adata_filename \u001b[38;5;241m=\u001b[39m local_data_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masap-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_team\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.final_adata.h5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m adata \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbacked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# add brain region to adata.obs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m obs \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/anndata/_io/h5ad.py:214\u001b[0m, in \u001b[0;36mread_h5ad\u001b[0;34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[0m\n\u001b[1;32m    212\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_h5ad_backed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_sparse_fmt \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (sparse\u001b[38;5;241m.\u001b[39mcsr_matrix, sparse\u001b[38;5;241m.\u001b[39mcsc_matrix):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDense formats can only be read to CSR or CSC matrices at this time.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/anndata/_io/h5ad.py:145\u001b[0m, in \u001b[0;36mread_h5ad_backed\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_h5ad_backed\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path, mode: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AnnData:\n\u001b[1;32m    143\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(filename\u001b[38;5;241m=\u001b[39mfilename, filemode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m--> 145\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     attributes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobsm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvarm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobsp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvarp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muns\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    148\u001b[0m     df_attributes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to synchronously open file (truncated file: eof = 5634523136, sblock->base_addr = 0, stored_eof = 8513565110)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 123 ms (started: 2025-03-06 08:58:30 +00:00)\n"
     ]
    }
   ],
   "source": [
    "adata_filename = local_data_path / f\"asap-{dataset_team}.final_adata.h5ad\"\n",
    "adata = sc.read_h5ad(adata_filename, backed=\"r\")\n",
    "\n",
    "# add brain region to adata.obs\n",
    "obs = adata.obs.copy()\n",
    "\n",
    "obs[\"brain_region\"] = obs[\"sample\"].map(br_mapper_full)\n",
    "obs[\"brain_region_simple\"] = obs[\"sample\"].map(br_mapper_simple)\n",
    "obs[\"case_id\"] = obs[\"sample\"].map(case_id_mapper)\n",
    "\n",
    "frontal_cells = obs[\"brain_region_simple\"] == \"frontal_ctx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e78213",
   "metadata": {},
   "source": [
    "### Subset to \"Case\" or \"Control\" samples\n",
    "\n",
    "Some of the contributed datasets include \"Other\" (e.g. 'prodromal PD') conditions besides \"Ideopathic Parkinson's\" and \"Healthy Control\".   We'll make a simplified dataset with just samples from Case (Parkinson's) and Control.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_control_cells = ~(obs[\"case_id\"] == \"Other\")  # exclude \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "include = frontal_cells & case_control_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561a836",
   "metadata": {},
   "source": [
    "\n",
    "NOTE: We read the full 2.7m Cells X 36k genes from an h5ad file, NOT into memory.  Here we are copying the 291k cells into memory and closing the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ba797",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_ad = adata[include].to_memory()\n",
    "adata.file.close()  # close the original adata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80323326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in any other metadata we'd like to use later?\n",
    "frontal_ad.obs[\"case_control\"] = frontal_ad.obs[\"sample\"].map(case_id_mapper)\n",
    "frontal_ad.obs[\"condition_id\"] = frontal_ad.obs[\"sample\"].map(condition_id_mapper)\n",
    "frontal_ad.obs[\"case_id\"] = frontal_ad.obs[\"sample\"].map(case_id_mapper)\n",
    "frontal_ad.obs[\"brain_region\"] = frontal_ad.obs[\"sample\"].map(br_mapper_simple)\n",
    "frontal_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487ddff",
   "metadata": {},
   "source": [
    "Now we have a much smaller ~300k cells to work with, roughtly balanced btween Case and Control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2347d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_ad.obs[\"case_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab8300",
   "metadata": {},
   "source": [
    "Export subset for merging with full gene expression to our `local_data_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf1e94-4eef-4117-9e95-09c397c36d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frontal_samples_filename = (\n",
    "    local_data_path / f\"asap-{dataset_team}.frontal_ctx_case_control_samples.h5ad\"\n",
    ")\n",
    "frontal_ad.write_h5ad(frontal_samples_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a260b708",
   "metadata": {},
   "source": [
    "Although we've subset to a much smaller dataset, we can see in our UMAP visualization that we have a wide ssampling of the overall gene expression latent space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(frontal_ad, basis=\"umap\", color=[\"case_control\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f9efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata, frontal_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcde23df-7c4d-4fb7-aeea-1aa2827a4bf3",
   "metadata": {},
   "source": [
    "## Compose subset `AnnData` summary object "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeff65c",
   "metadata": {},
   "source": [
    "### Copy dataset `anndata` to workspace \n",
    "\n",
    "Loading the dataset directly from the gcp bucket is inefficient.  Lets first copy it to our workspace files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aeffcc-ca9c-478e-9cae-ee9218c036f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_adata_filename = (\n",
    "    cohort_analysis_path / f\"asap-{dataset_team}.merged_adata_object.h5ad\"\n",
    ")\n",
    "l_full_adata_filename = (\n",
    "    local_data_path / f\"asap-{dataset_team}.merged_adata_object.h5ad\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b007250-d436-4835-9760-85ad5474a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not l_full_adata_filename.exists():\n",
    "    !cp {full_adata_filename} {l_full_adata_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e91840-a4b7-4586-bc54-77b931d3b0d5",
   "metadata": {},
   "source": [
    "### Load _full_ gene expression \n",
    " \n",
    "We'll construct an adata having the full (not limited to highly variable genes) gene expression, by combining the the subset adata (with all the embeddings and analyses) with the `asap-cohort.merged_adata_object.h5ad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce17539",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_adata = sc.read_h5ad(l_full_adata_filename, backed=\"r\")\n",
    "\n",
    "frontal_samples_filename = (\n",
    "    local_data_path / f\"asap-{dataset_team}.frontal_ctx_case_control_samples.h5ad\"\n",
    ")\n",
    "frontal_ad = sc.read_h5ad(frontal_samples_filename, backed=\"r\")\n",
    "\n",
    "var_ = full_adata.var.copy()\n",
    "X = full_adata[frontal_ad.obs_names].X.copy()\n",
    "\n",
    "full_adata.file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc4a1b",
   "metadata": {},
   "source": [
    "Now we can combine the _full_ gene expression matrix wit ouyr frontal cortex subset, and save the resulting `AnnData`object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_full_ad = sc.AnnData(\n",
    "    X=X,\n",
    "    obs=frontal_ad.obs,\n",
    "    var=var_,\n",
    "    uns=frontal_ad.uns,\n",
    "    obsm=frontal_ad.obsm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1a3fd",
   "metadata": {},
   "source": [
    "### Export full frontal cortex `AnnData` object for further analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89d66a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frontal_full_samples_filename = (\n",
    "    local_data_path / f\"asap-{dataset_team}.full_frontal_ctx_case_control_samples.h5ad\"\n",
    ")\n",
    "frontal_full_ad.write_h5ad(frontal_full_samples_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068a07e-a0f2-4138-aea5-fc33a08652fb",
   "metadata": {},
   "source": [
    "-----------------\n",
    "# Next:   \n",
    "Continue with:\n",
    "- Part 3 - Gene of interest analysis (__Workshop Activity__) [03_GOI_analysis.ipynb](./03_GOI_analysis.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ff285-4fda-4749-97b5-26a07c537c31",
   "metadata": {},
   "source": [
    "--------------------\n",
    "# Provenance\n",
    "Generate information about this notebook environment and the packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64005efc-83be-467d-8673-62fa6fcbdca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355aaf0f-c1ce-42f6-ba39-e6be358e8df0",
   "metadata": {},
   "source": [
    "pip installed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17a059-7f0d-4348-b89d-102b89c06eba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85446495-4def-4f49-ad33-ee5ad56d7986",
   "metadata": {},
   "source": [
    "JupyterLab extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ce13f-06ee-462d-8357-acd1970de3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066c8d0-e3c5-4224-88a3-e42e9e31e93a",
   "metadata": {},
   "source": [
    "Number of cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2e747-6967-40cc-b38c-36ca1b45b121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!grep ^processor /proc/cpuinfo | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde8571-0073-48f6-9210-1d653695a0cf",
   "metadata": {},
   "source": [
    "Memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78bb0e2-525a-40ac-b313-28c4e32bcda6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!grep \"^MemTotal:\" /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b56d3b-a561-4c05-936b-679e36b02fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba77b6e-378d-4c11-9185-690523da2fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d23df-79ea-4e76-91d0-104c3c8d5e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
